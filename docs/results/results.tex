\documentclass[letterpaper]{article}
\setlength{\columnsep}{0.75cm}
\usepackage{python}
\usepackage{algorithm2e}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{framed, color}
\usepackage{soul}
\definecolor{shadecolor}{rgb}{.93,.93,.93}
\definecolor{blu}{rgb}{0,0,1}
\newcommand{\td}[1]{{\color{blu}\hl{TODO: #1}}}
\definecolor{shadecolor}{rgb}{.93,.93,.93}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{gensymb}
\usepackage[hmargin=1in,vmargin=1in]{geometry}
\setlength{\parindent}{0cm}
\setlength{\parskip}{4mm plus1mm minus1mm}
\usepackage[
	colorlinks=true,
	urlcolor=blue
]{hyperref}

\title{}
\author{}
 
\parindent0pt \parskip8pt
\begin{document}
\maketitle
\section{Classifier competence as a function of image}

\begin{center}
\includegraphics[scale=0.65]{../figs/longitude_cult-ing-img.pdf}
\end{center}


The above figure investigates the ability of a naive bayes classifier to 
classify workers who were primed under different treatments.   
We perform binary classification of workers drawn 
from either the cultural-images or ingredients-images treatments.

We train the classifier to perform a binary classification between workers 
from the two treatments, providing it 80 randomly selected workers from 
both treatments as a training set, and using 20 workers to test.  We train
the classifier using only the labels that workers provided for one of the
test images, and provide the classifier's performance results for when using
different images as the basis of classification.  

For each such test of the classifier, we look at two cases, one in which we
treat each text input associated to an image in the HIT as as distinguished
source of featuers (tokens), and one in which no distinction is made between
the 5 text inputs associated to an image.  We denote the former as a 
classifier test with ``position-based features'', and the latter with 
``position-less featuers''.  So, in a test of the classifier with 
position-based features, an entry of ``soup'' into the first 
text input is regarded distinct from an entry of  ``soup'' into the second 
text input, whereas in a test with position-less features
these two token occurences are encoded as one and the same feature.

\begin{center}
\includegraphics[scale=0.65]{../figs/longitude_cult-ing-fund.pdf}
\end{center}
This figure is similar to the previous one, but it compares the cultural-funder
and ingredients-funder treatments.

\begin{center}
\includegraphics[scale=0.65]{../figs/longitude_cult-ing-img-fund.pdf}
\end{center}
And this one compares the cultural-funder-image and ingredients-funder-image
treatments

\begin{center}
\includegraphics[scale=0.65]{../figs/cross-classification.pdf}
\end{center}
The above figure shows that, from the perspective of being able to distinguish
priming treatments using a naive bayes classifier, in-task priming is has as
great an effect as prominent disclusure of the research funder.

\begin{center}
\includegraphics[scale=0.65]{../figs/valenceComparison.pdf}
\end{center}
The above figure shows the effect of the various priming treatments in terms
of the number of culture-related and food-related words used.

\end{document}


