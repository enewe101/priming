manuscript notes
~~~~~~~~~~~~~~~~

Galaxy zoo refs:
Galaxy Zoo Volunteers Share Pain and Glory of Research
Galaxy Zoo: Motivations of Citizen Scientists, Raddick+ 2013.
Galaxy Zoo: Exploring the Motivations of Citizen Science Volunteers, Raddick+ 2010

Further data processing needs:
x ensure that graphting onto wn is done mutually
x ensure that _-words get split during spell correction
x ensure that alias substitutions are made after spell correction
x insert unrecognized objects into the wordnet ontology somehow...
X check validity of food-detector
X how can we check validity of specificity measurements?
x update all analyses to reflect spell checking with allrecipes words
	x classifier performance
	x proportion food
	x vocab size
	x relative specificity
[] cleanup data
	[] eliminate unused functions and analyses
	[] standardize the naming of treatments
	[] decide if I should get rid of references to the first treatment.

[] establish confidence intervals and significance tests for all analyses
	x classifier performance
	x proportion food
	X vocab size
	[] relative specificity

[] try reproducing food-classification data using only food.n.01 and food.n.02
	or else reflect the choice to include more root synsets to define food
	in the description within the supplementary material

Decided to use
	- lemmatization
	- stop-word removal
	- preserve word location

Results
	- Strength of inter-task and framing effects
	- Persistence of Inter-task effects 
	- Variations in the susceptibility of tasks
	- Effects on the direction of focus
	- Effects on specificity
Discussion
	- An approach to fine qualifications
	- Classifiers as distinguishers

x make a plot of aggregate distinguishability
x make a plot of average distinguishability as a function of image
x and as a function of position

[] plot the relative foodiness
[] plot the relative specificity
	- to do this, the relative specificity needs to be put on an even footing
		- one word should get one vote (makes a contribution in [-1,1]
		- the final value should be reported as a value in [-1,1]


Notes about specificity
	- The initial hypothesis was that greater similarity between initial
		and test tasks gives more specificity of labels
	- But, even for the food/obj comparison, we see that the food treatment
		is significantly more specific.  The affect is at about the same
		strength as for the food/cult comparison.
	- So it seems that this might be related to the food concept, not the
		degree of similarity between initial and test tasks.
	- Corroborating this is the fact that framing tasks to the identification
		of food also increases specificity
	- We see the same pattern of results when we use vocabulary size as 
		a proxy for specificity
	- So, does this really just reflect the greater vocabulary for food?
		Does initial and test task similarity play a role at all?
		

- A second take on an introduction
Humans outperform sophisticated artificial intelligence algorithms in many
tasks, especially ones requiring general knowledge about the world, 
qualitative judgment, and visuo-spatial reasoning.  Recently, microtask
web platforms have entered the programmer's toolkit, in effect allowing one
to import human judgment into an algorithm.  Some computer scientists consider
such platforms to be a new computing architecture, but people are very
different from electronic processors.  Peoples responses vary, and this stands
as a barrier to a formal treatment of human computation.  We provide a 
formal characterization of priming effects and introduce a technique
for measuring priming.  We apply this technique to investigate an unforseen 
source of bias: the bias induced by one task on another.  Surprisingly
we found these \textit{inter-task effects} to be more severe than 
\textit{framing}, a more well-studied form of priming.


[] reduce the number of pannels shown in figure 1
[] quote precise results for priming effects in experiment 1 for the NB classifier
[] " " " for degree of food orientation using wordnet on experiment 1
[] " " " for degree of specificity using experiment 1
[] experiment 2 to discuss the effects of having no prior tasks for the framing 
	treatment
[] experiment 2 to investigate the temporal profile of inter-task effects.


OOO
===
6) Clean up the ontology
7) Re-run the analyses with cleaned ontology
2) Make a pass on manuscript
	- refs
	- typos / explanation / enough psych background?
3) Fill in Methods
4) Create suppl matl
5) Why do I get high variance for specificity comparisons?

Refs
====

- workers prefer to do tasks in batches
- why our task is a canonical task.  Why choose image labeling for this 
	investigation?
- support for our implementation of framing -- why would we expect that to
	cause workers to provide more labels for this "preferred content"?


- existing work on priming focuses on the internal psychological mechanisms of 
	priming
- Typically priming is operationalized as a decrease in the liminal level of
	stimuli / recognition
- fMRI has been used 
- definition of negative priming


- object similarity is not transitive
	


- Naive Bayes is easy to implement and works accross a broad range of tasks



% Priming
	- Priming is based on matching *time* \cite{beller1971priming}
	- Priming can be due to more rapid stimulus encoding and memory access.
		for memory dep tasks, it may be due to putting LTM info into STM
		\cite{beller1971priming}
	- Stimulus encoding is a constructive process.  participants may be 
		"using the advance information to preconstruct an internal structure"
		"... which leaves just a small amount of filling in".
		\cite{beller1971priming}

% AMT
	- motivations
		- entertainment
			- \cite{5543192}

	- general concerns about quality and external validity
		\cite{Berinsky2012351}
		\cite{paolacci2010running}
	- factors
		- effects of ranking performance
			probably Barankay, 2010 "Rankings and Social Tournaments: 
				Evidence from a Field Experiment". University of Pennsylvania 
				Mimeo.
		- money
			\cite{Finnerty2013}
			\cite{5543192}
			\cite{kazai2013analysis}

		- bundling tasks
			- for a colour-recognition task, HPUs performed like a 
				3-way core procesor
				

		- UI and UX design (simple vs complex)
			\cite{Finnerty2013}

		- language used in instructions
			\cite{Finnerty2013}

		- task complexity / effort
			\cite{kazai2013analysis}
			\cite{Finnerty2013}

		- screening / qualifications
			\cite{kazai2013analysis}
			\cite{paolacci2010running}

	- image labeling is a "typical task"
		\cite{chandler2013breaking}
		\cite{Berinsky2012351}
		\cite{Finnerty2013}
		\cite{paolacci2010running}

		- long term role of HPUs is in computer vision rleated tasks
			\cite{5543192}

		- Computer vision has many unsolved tasks for which CPU-based algs 
			are not robust and are computationally intensive, yet for HPUs
			these tasks are easy
			\cite{5543192}
			- e.g. quality assesment
				

		probably Barankay, 2010 "Rankings and Social Tournaments: 
			Evidence from a Field Experiment". University of Pennsylvania 
			Mimeo.
		- for medical images
			\cite{chandler2013breaking}
		- "image labeling tasks are among the most commonly performed tasks 
			on MTurk" \cite{chandler2013breaking}

	- audio transcription and linguistic analysis
		\cite{chandler2013breaking}
		\cite{paolacci2010running}

	- transcription of handwriting
		\cite{Berinsky2012351}
		\cite{Finnerty2013}

	- categrizing / labeling data
		\cite{Finnerty2013}
		\cite{5543192}

	- as a way to do online experiments
		probably \cite{horton2010labor}
		\cite{Berinsky2012351}
		\cite{chandler2013breaking}
		\cite{paolacci2010running}

		- fast and cheap
			\cite{Finnerty2013}
			\cite{chandler2013breaking}
			\cite{Berinsky2012351}**

% Possibly related to inter-task effects:
Transue, John E., Daniel J. Lee, and John H. Aldrich. 2009. Treatment spillover effects across survey experiments
	
	

Manuscript Notes
================

- address the heavy usage of data from the first image.
- "we drop funding from the discussion"
- continue to use the treatment symbols throughout, its more concise
- check that the two 'marginally significant' image-based distinctions really
	are marginally significant


Do Now
======

- Data Stuff
	x implement k-fold cross-validation
	x plot the new \theta_NB data and check for singificance
		x include all comparisons (e.g. comparing one funding treatment to the 
			other
	x make new longitudinal plot of \theta_NB and check for significance
		x compare cult_img and ambg
	x Check where the 95% confidence level is for binary classification with
		test set of 25

	x It would be best to plot averages for the cross-val data, because
		different runs produce different levels: some look much better
		than others, but it's not right to cherry pick!  An average would
		be most representational

	x assess significance tests for the orientation composition measures
		o I would feel better about using the stdev of 'food_nx' (food non 
			exclusive)... maybe...
	x re-plot the longitudinal excess cutural orientation
	[] crossComparison got rid of numReplicates -- propogate
	x review the calculation of significance for the specificity comparisons
		x I think I have the variance calculated correctly now
		x have a look at the plots of specificity comparisons
			[] one thing that has me concerned is that the variance didn't seem
				to be lower in the plots, although the variance printouts
				at runtime are lower...
		[] perform all comparisons
		x the mask approach is not working.  Desired behavior: e.g. for 
			cultural specificity comparison, use any tokens that have a 
			cultural ancestor and no food ancestor
			x implemented a 'mask' and a 'drop' feature

	x re-plot the specificity comparisons.  Done for pools of 50.  The one for 
		pools of 124 runs forever
		[] once the ontology is reworked, do it on a per-image basis, and only
			run the comparison of ambg <-> cult_img for the images other than
			'test0' (for 'test0', run all comparisons).
		~ I started running this even though ontology isn't worked out

	[] consider making the brief specificity comparison be based on only
		first image

	[] then the allpairs specificity comparison plot in the suppl mat'l shoul
		maybe be based only on the first image

	x make a longitudinal specificity plot for ambg <-> cult_img
		[] tack this on to the other longitudinal plots (but wait for data
			availability)

	[] rework the ontology, and regenerate all data

	x push together the longitudinal plots into one figure (for binary 
		classification performance and excess cultural orientation).  Add a
		separate subplot for the excess cultural orientation, calculated for
		alltreatments.
	x make a briefer plot in place of the plotAllSpecificityComparisons, which
		just shows that the similarity of the initial image set to the final
		image set dictates specificity

	x make all plots show the 95% CI

	x optimize an svm classifier to tell apart the inter-task priming
		using the exp1 data.
		x optimal parameters for svm might depend on the number of dimensions
			prefer to maximize the accuracy of single-image classifications
			accross the range of images, rather than a 1-off multi-image
			classification

	x correct spelling mistakes
	x try using hypernyms

	[] create figures to show the new results
		[] as a function of image
		[] as a function of position
		=> does it look like positional effects are interesting
		=> does it look like inter-image primability exists?
		

[x] Ontology
	- the ontology needs to be cleaned up
	- I noticed that there are some orphans

- check back for my math stack exchange answer
	=> added a bounty
	=> posted on cross-validated

- statistical significance for theta_NB
	- re-calculate for testing set of 40.  Wasn't enough
	- re-calculate for testing set of 50.

- hypothesis testing for orientation and excess culture

- hypothesis testing for specificity

- methods

- plot 8 should compare cult_img and ingr_img instead of cult_img and ambg

- read *the future of crowd work*

Other stuff
===========

- am I using a consistent training and test size?

- the excess cultural orientation should be calculated with a fixed subsample
	from each treatment, because the treatments aren't the exact same size.


Might include
============
* never compared total vocab...
* compare total vocabulary between different treatments, and between a 
	population comprised of 50 users from cultural and 50 users from 
	ingredients


Notes about ref inclusions
=========================
I included ref \cite{Swaab200299} to support the claim that people are susceptible to priming, but I need to re-check that ref.
