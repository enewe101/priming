OOO
===
6) Clean up the ontology
7) Re-run the analyses with cleaned ontology
2) Make a pass on manuscript
	- refs
	- typos / explanation / enough psych background?
3) Fill in Methods
4) Create suppl matl
5) Why do I get high variance for specificity comparisons?

Refs
====

- workers prefer to do tasks in batches
- why our task is a canonical task.  Why choose image labeling for this 
	investigation?
- support for our implementation of framing -- why would we expect that to
	cause workers to provide more labels for this "preferred content"?


- existing work on priming focuses on the internal psychological mechanisms of 
	priming
- Typically priming is operationalized as a decrease in the liminal level of
	stimuli / recognition
- fMRI has been used 
- definition of negative priming


- object similarity is not transitive
	


- Naive Bayes is easy to implement and works accross a broad range of tasks



% Priming
	- Priming is based on matching *time* \cite{beller1971priming}
	- Priming can be due to more rapid stimulus encoding and memory access.
		for memory dep tasks, it may be due to putting LTM info into STM
		\cite{beller1971priming}
	- Stimulus encoding is a constructive process.  participants may be 
		"using the advance information to preconstruct an internal structure"
		"... which leaves just a small amount of filling in".
		\cite{beller1971priming}

% AMT
	- motivations
		- entertainment
			- \cite{5543192}

	- general concerns about quality and external validity
		\cite{Berinsky2012351}
		\cite{paolacci2010running}
	- factors
		- effects of ranking performance
			probably Barankay, 2010 "Rankings and Social Tournaments: 
				Evidence from a Field Experiment". University of Pennsylvania 
				Mimeo.
		- money
			\cite{Finnerty2013}
			\cite{5543192}
			\cite{kazai2013analysis}

		- bundling tasks
			- for a colour-recognition task, HPUs performed like a 
				3-way core procesor
				

		- UI and UX design (simple vs complex)
			\cite{Finnerty2013}

		- language used in instructions
			\cite{Finnerty2013}

		- task complexity / effort
			\cite{kazai2013analysis}
			\cite{Finnerty2013}

		- screening / qualifications
			\cite{kazai2013analysis}
			\cite{paolacci2010running}

	- image labeling is a "typical task"
		\cite{chandler2013breaking}
		\cite{Berinsky2012351}
		\cite{Finnerty2013}
		\cite{paolacci2010running}

		- long term role of HPUs is in computer vision rleated tasks
			\cite{5543192}

		- Computer vision has many unsolved tasks for which CPU-based algs 
			are not robust and are computationally intensive, yet for HPUs
			these tasks are easy
			\cite{5543192}
			- e.g. quality assesment
				

		probably Barankay, 2010 "Rankings and Social Tournaments: 
			Evidence from a Field Experiment". University of Pennsylvania 
			Mimeo.
		- for medical images
			\cite{chandler2013breaking}
		- "image labeling tasks are among the most commonly performed tasks 
			on MTurk" \cite{chandler2013breaking}

	- audio transcription and linguistic analysis
		\cite{chandler2013breaking}
		\cite{paolacci2010running}

	- transcription of handwriting
		\cite{Berinsky2012351}
		\cite{Finnerty2013}

	- categrizing / labeling data
		\cite{Finnerty2013}
		\cite{5543192}

	- as a way to do online experiments
		probably \cite{horton2010labor}
		\cite{Berinsky2012351}
		\cite{chandler2013breaking}
		\cite{paolacci2010running}

		- fast and cheap
			\cite{Finnerty2013}
			\cite{chandler2013breaking}
			\cite{Berinsky2012351}**

% Possibly related to inter-task effects:
Transue, John E., Daniel J. Lee, and John H. Aldrich. 2009. Treatment spillover effects across survey experiments
	
	

Manuscript Notes
================

- address the heavy usage of data from the first image.
- "we drop funding from the discussion"
- continue to use the treatment symbols throughout, its more concise
- check that the two 'marginally significant' image-based distinctions really
	are marginally significant


Do Now
======

- Data Stuff
	x implement k-fold cross-validation
	x plot the new \theta_NB data and check for singificance
		x include all comparisons (e.g. comparing one funding treatment to the 
			other
	x make new longitudinal plot of \theta_NB and check for significance
		x compare cult_img and ambg
	x Check where the 95% confidence level is for binary classification with
		test set of 25

	x It would be best to plot averages for the cross-val data, because
		different runs produce different levels: some look much better
		than others, but it's not right to cherry pick!  An average would
		be most representational

	x assess significance tests for the orientation composition measures
		o I would feel better about using the stdev of 'food_nx' (food non 
			exclusive)... maybe...
	x re-plot the longitudinal excess cutural orientation
	[] crossComparison got rid of numReplicates -- propogate
	x review the calculation of significance for the specificity comparisons
		x I think I have the variance calculated correctly now
		x have a look at the plots of specificity comparisons
			[] one thing that has me concerned is that the variance didn't seem
				to be lower in the plots, although the variance printouts
				at runtime are lower...
		[] perform all comparisons
		x the mask approach is not working.  Desired behavior: e.g. for 
			cultural specificity comparison, use any tokens that have a 
			cultural ancestor and no food ancestor
			x implemented a 'mask' and a 'drop' feature

	x re-plot the specificity comparisons.  Done for pools of 50.  The one for 
		pools of 124 runs forever
		[] once the ontology is reworked, do it on a per-image basis, and only
			run the comparison of ambg <-> cult_img for the images other than
			'test0' (for 'test0', run all comparisons).
		~ I started running this even though ontology isn't worked out

	[] consider making the brief specificity comparison be based on only
		first image

	[] then the allpairs specificity comparison plot in the suppl mat'l shoul
		maybe be based only on the first image

	x make a longitudinal specificity plot for ambg <-> cult_img
		[] tack this on to the other longitudinal plots (but wait for data
			availability)

	[] rework the ontology, and regenerate all data

	x push together the longitudinal plots into one figure (for binary 
		classification performance and excess cultural orientation).  Add a
		separate subplot for the excess cultural orientation, calculated for
		alltreatments.
	x make a briefer plot in place of the plotAllSpecificityComparisons, which
		just shows that the similarity of the initial image set to the final
		image set dictates specificity

	x make all plots show the 95% CI
		

[] Ontology
	- the ontology needs to be cleaned up
	- I noticed that there are some orphans

- check back for my math stack exchange answer
	=> added a bounty
	=> posted on cross-validated

- statistical significance for theta_NB
	- re-calculate for testing set of 40.  Wasn't enough
	- re-calculate for testing set of 50.

- hypothesis testing for orientation and excess culture

- hypothesis testing for specificity

- methods

- plot 8 should compare cult_img and ingr_img instead of cult_img and ambg

- read *the future of crowd work*

Other stuff
===========

- am I using a consistent training and test size?

- the excess cultural orientation should be calculated with a fixed subsample
	from each treatment, because the treatments aren't the exact same size.


Might include
============
* never compared total vocab...
* compare total vocabulary between different treatments, and between a 
	population comprised of 50 users from cultural and 50 users from 
	ingredients


Notes about ref inclusions
=========================
I included ref \cite{Swaab200299} to support the claim that people are susceptible to priming, but I need to re-check that ref.
